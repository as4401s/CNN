{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, GlobalMaxPooling2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10= tf.keras.datasets.cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)= cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0\n",
    "\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = len(set(y_train))    #number of classes\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model - inspiration from vgg model\n",
    "\n",
    "i = Input(shape= x_train[0].shape)\n",
    "\n",
    "x = Conv2D(32, (3,3), activation='relu', padding = 'same')(i)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(32, (3,3), activation='relu', padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(2,2)(x)\n",
    "x = Conv2D(64, (3,3), activation='relu', padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, (3,3), activation='relu', padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(2,2)(x)\n",
    "x = Conv2D(128, (3,3), activation='relu', padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(128, (3,3), activation='relu', padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(2,2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(K, activation = 'softmax')(x)\n",
    "\n",
    "model = Model(i,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 209s 4ms/sample - loss: 1.3213 - accuracy: 0.5331 - val_loss: 0.9336 - val_accuracy: 0.6719\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 208s 4ms/sample - loss: 0.8708 - accuracy: 0.7024 - val_loss: 0.8694 - val_accuracy: 0.7022\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 208s 4ms/sample - loss: 0.7029 - accuracy: 0.7622 - val_loss: 0.8063 - val_accuracy: 0.7206\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 209s 4ms/sample - loss: 0.5867 - accuracy: 0.8019 - val_loss: 0.7143 - val_accuracy: 0.7602\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 209s 4ms/sample - loss: 0.4987 - accuracy: 0.8316 - val_loss: 0.7698 - val_accuracy: 0.7523\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 209s 4ms/sample - loss: 0.4159 - accuracy: 0.8605 - val_loss: 0.6271 - val_accuracy: 0.8031\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 209s 4ms/sample - loss: 0.3530 - accuracy: 0.8825 - val_loss: 0.6296 - val_accuracy: 0.8021\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 208s 4ms/sample - loss: 0.3054 - accuracy: 0.8981 - val_loss: 0.6298 - val_accuracy: 0.8184\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 208s 4ms/sample - loss: 0.2633 - accuracy: 0.9117 - val_loss: 0.6641 - val_accuracy: 0.8116\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 208s 4ms/sample - loss: 0.2285 - accuracy: 0.9245 - val_loss: 0.6790 - val_accuracy: 0.8102\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 209s 4ms/sample - loss: 0.2025 - accuracy: 0.9337 - val_loss: 0.6908 - val_accuracy: 0.8132\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 208s 4ms/sample - loss: 0.1764 - accuracy: 0.9426 - val_loss: 0.7064 - val_accuracy: 0.8173\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 208s 4ms/sample - loss: 0.1636 - accuracy: 0.9464 - val_loss: 0.7675 - val_accuracy: 0.8089\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 208s 4ms/sample - loss: 0.1463 - accuracy: 0.9537 - val_loss: 0.7179 - val_accuracy: 0.8190\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 211s 4ms/sample - loss: 0.1398 - accuracy: 0.9542 - val_loss: 0.8053 - val_accuracy: 0.8216\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(x_train,y_train, validation_data=(x_test, y_test), epochs= 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1562/1562 [==============================] - 330s 211ms/step - loss: 1.4670 - accuracy: 0.4849 - val_loss: 1.1231 - val_accuracy: 0.6148\n",
      "Epoch 2/50\n",
      "1562/1562 [==============================] - 335s 215ms/step - loss: 0.9989 - accuracy: 0.6536 - val_loss: 0.9559 - val_accuracy: 0.6690\n",
      "Epoch 3/50\n",
      "1562/1562 [==============================] - 330s 211ms/step - loss: 0.8595 - accuracy: 0.7073 - val_loss: 0.7978 - val_accuracy: 0.7268\n",
      "Epoch 4/50\n",
      "1562/1562 [==============================] - 330s 211ms/step - loss: 0.7609 - accuracy: 0.7424 - val_loss: 0.8078 - val_accuracy: 0.7269\n",
      "Epoch 5/50\n",
      "1562/1562 [==============================] - 330s 211ms/step - loss: 0.6994 - accuracy: 0.7646 - val_loss: 0.6673 - val_accuracy: 0.7773\n",
      "Epoch 6/50\n",
      "  51/1562 [..............................] - ETA: 4:55 - loss: 0.6478 - accuracy: 0.7892"
     ]
    }
   ],
   "source": [
    "# data augmentation\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "data_generator= ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip = True)\n",
    "train_generator= data_generator.flow(x_train, y_train, batch_size)\n",
    "steps_per_epoch = x_train.shape[0] // batch_size\n",
    "r = model.fit_generator(train_generator, validation_data=(x_test, y_test), steps_per_epoch = steps_per_epoch, epochs= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
